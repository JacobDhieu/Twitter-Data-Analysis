{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "JupyterNotebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacobDhieu/Twitter-Data-Analysis/blob/main/JupyterNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dalGw91ZYpmi"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import string\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLH6mtRVYpmn"
      },
      "source": [
        "#data loader class\n",
        "class DataLoader:\n",
        "  def __init__(self,dir_name,file_name):\n",
        "    self.dir_name=dir_name\n",
        "    self.file_name = file_name\n",
        "    \n",
        " \n",
        "  def read_csv(self):\n",
        "    os.chdir(self.dir_name)\n",
        "    tweets_df=pd.read_csv(self.file_name)\n",
        "    return tweets_df\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWkewDuTYpmo"
      },
      "source": [
        "#object creation\n",
        "DataLoader_obj= DataLoader('drive/MyDrive/data','cleaned_fintech_data.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "S9vgvEpOYpmo",
        "outputId": "c8670b89-0b8a-437d-84dd-7d8da195a60e"
      },
      "source": [
        "tweets_df=DataLoader_obj.read_csv()\n",
        "tweets_df.dropna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: '/Desktop/10Academy/Day2'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-9b63d5d8f18b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDataLoader_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-14-754525e5b672>\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtweets_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/Desktop/10Academy/Day2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBaimtZBYpmp"
      },
      "source": [
        "len(tweets_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFCk1sxYpmq"
      },
      "source": [
        "class PrepareData:\n",
        "  def __init__(self,df):\n",
        "    self.df=df\n",
        "    \n",
        "  def preprocess_data(self):\n",
        "    tweets_df = self.df.loc[self.df['lang'] ==\"en\"]\n",
        "\n",
        "    \n",
        "    #text Preprocessing\n",
        "    tweets_df['clean_text']=tweets_df['clean_text'].astype(str)\n",
        "    tweets_df['clean_text'] = tweets_df['clean_text'].apply(lambda x: x.lower())\n",
        "    tweets_df['clean_text']= tweets_df['clean_text'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))\n",
        "    \n",
        "    #Converting tweets to list of words For feature engineering\n",
        "    sentence_list = [tweet for tweet in tweets_df['clean_text']]\n",
        "    word_list = [sent.split() for sent in sentence_list]\n",
        "\n",
        "    #Create dictionary which contains Id and word \n",
        "    word_to_id = corpora.Dictionary(word_list)\n",
        "    corpus_1= [word_to_id.doc2bow(tweet) for tweet in word_list]\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    return word_list, word_to_id, corpus_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRqwOwavYpmr"
      },
      "source": [
        "PrepareData_obj=PrepareData(tweets_df)\n",
        "word_list ,id2word,corpus=PrepareData_obj.preprocess_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8fwNq5MYpmr"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXrZXhLsYpms"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=5, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duzpJ8O1Ypms"
      },
      "source": [
        "pprint(lda_model.show_topics(formatted=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SdFDIbyYpmt"
      },
      "source": [
        "# Compute Perplexity\n",
        "\n",
        "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
        "doc_lda = lda_model[corpus]\n",
        "\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNIw6jViYpmt"
      },
      "source": [
        "!pip install pyLDAvis "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCGhHAp7Ypmu"
      },
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pickle \n",
        "import pyLDAvis\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "LDAvis_prepared"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}